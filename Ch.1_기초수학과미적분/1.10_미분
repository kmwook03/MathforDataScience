## 미분 (derivative)
> 어떤 함수의 정의역 속 각 점에서 함숫값의 변화량과 독립 변숫값의 변화량 비의 극한들로 치역이 구성되는 새로운 함수. 도함수라고도 함.
> -> 함수의 기울기, 어느 지점에서의 변화율 측정에 유용함.

$$
\frac{d}{dx} x^a = ax^{a-1},\ 
\frac{d}{dx}f(x) = f^{\prime}(x)
$$

## 편미분 (partial derivative)
다변수 함수의 특정 변수를 상수로 간주하여 미분함.
다차원의 기울기(그레이디언트; gradient)를 구함.

미분 대상이 아닌 변수는 상수 취급 한다.
$$
f(x,y)=2x^3 + 3y^3\\
\ \\
\frac{\partial}{\partial x}f(x,y) = 6x^2\\
\ \\
\frac{\partial}{\partial y}f(x,y) = 9y^2
$$

- 파이썬 편미분 실습

```python
from sympy import *
from sympy.plotting import plot3d

x, y = symbols('x y')

f = 2*x**3 + 3*y**3

dx_f = diff(f, x)
dy_f = diff(f, y)

print(dx_f) # 6*x**2
print(dy_f) # 9*y**2

# 함수 그래프 그리기
plot3d(f, (x, -10, 10), (y, -10, 10))
```

## 연쇄 법칙 (chain rule)

다음 두 개의 함수가 있다.
$$
y = x^2 + 1
z = y^3 - 2
$$

첫 번째 함수에서 y는 출력 변수이지만 두 번째 함수에서는 입력 변수이기 때문에 이 두 함수는 연결되어 있다.
-> 첫 번째 함수 y를 두 번째 함수 z에 대입이 가능하다.

$$
z = (x^2 + 1)^3 - 2
$$

이를 통해 x에 대한 z의 도함수를 구할 수 있다.

$$
\frac{d}{dx}z=\frac{d}{dx}((x^2 + 1)^3 - 2)=6x(x^2+1)^2
$$

**다른 접근: 각각의 도함수를 구한 후 곱하기**

즉, $$
\frac{dz}{dx}=\frac{dy}{dx}\times \frac{dz}{dy}
$$

연쇄 법칙은 신경망 훈련 시 적절한 가중치와 편향을 갖도록 하는 데 핵심이 되는 부분.
각 층의 도함수를 풀어서 연결해야 하기 때문.